**Rank** - 
- Maximum number of its **Linearly Independent Columns**
	- dimension of the subspace generated by its columns
	- $rank(A) = rank(L_A) = dim(R(L_A))$ 
	- $R(L_A) = span(L_A(\beta)) = span(\{L_A(e_1), \cdots ,L_A(e_n)\})$
	- $L_A(e_j) = Ae_j = a_j$ where $a_j$ is tje $j^{th}$  column of $A$ 
	- Hence $R(L_A) = span(\{a_1,a_2, \cdots , a_n\}$  
	- thus 
$$
\begin{aligned}
rank(A) &= rank(L_A)\\ 
&= dim(R(L_A))\\
&= dim(span(\{a_1,a_2, \cdots , a_n\})

\end{aligned}
$$
- <u>an</u> $n\times n$ <u>matrix is invertible is and only if its rank is</u> $n$


Example 1

Let
$$
A =
\begin{pmatrix}
1 & 0 & 1\\
0 & 1 & 1\\
1 & 0 & 1
\end{pmatrix}
$$
Observe that the first and second columns of $A$
- are linearly independent 
and that third column is a linear combination of the first two. Thus,
$$
rank(A) = dim\left(span\left(\left\{\begin{pmatrix}
1\\
0\\
0
\end{pmatrix},
\begin{pmatrix}
0\\
1\\
0
\end{pmatrix},
\begin{pmatrix}
1\\
1\\
1
\end{pmatrix} \right\}\right)\right) = 2
$$
To compute **the rank** of matrix $A$ 
- Do it after elementary row and column operations (RREF). So that number if linearly independent columns is obvious. 

#### **Theorem 3.6**

Let $A$ be an $m\times n$ matrix of rank $r$.
Then,
- $r\leq m,$
- $r\leq n$ 
- and by a finite number of elementary row and column operations can be transformed into the matrix 
$$
D =
\begin{pmatrix}
I_r & O_1\\
O_2 & O_3
\end{pmatrix}
$$
- Where $O_1, O_2, O_3$ are zero matrices.
Thus, $D_{ii} = 1\quad \text{ for } i\leq r \text{ and } D_{ij} =0$  
$$
\begin{cases}
D_{ii} = 1 \quad \text{ for } i\leq r \\
D_{ij} = 0 \quad \text{ otherwise}
\end{cases}
$$

Example 3

Consider the matrix 
$$
A =
\begin{bmatrix}
0 & 2 & 4 & 2 & 2\\
4 & 4 & 4 & 8 & 0\\
8 & 2 & 0 & 10 & 2\\
6 & 3 & 2 & 9 & 1
\end{bmatrix}
$$
By means of  successive elementary row and column operations, we can transform $A$ into matrix $D$ as in [[3.2 The Rank Of A Matrix and Matrix Inverses#^44ac4e|Theorem 3.6]] 

which results in the matrix 
$$
D =
\begin{bmatrix}
1 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 0 & 0\\
\end{bmatrix}
$$

$rank(D) = 3$ so, $rank(A) =3$ 


**Corollary 1** : 
Let $A$ be an $m\times n$ matrix of $rank(A) = r$ 
Then there exist invertible matrices $B$ and $C$ of sizes $m\times m$ and $n\times n$ 
Such that, $D = BAC$ 
where, 
$$
D =
\begin{pmatrix}
I_r & O_1\\
O_2 & O_3
\end{pmatrix}
$$
is the $m\times n$ matrix in which $O_1, O_2,$ and $O_3$ are zero matrices

There exist elementary matrices $E_1, E_2,\cdots, E_P$  
and element matrices $G_1, G_2, \cdots , G_q$ such that
$$D = E_pE_{p-1}\cdots E_2E_1AG_1G_2\cdots G_q$$
Each $E_j$ and $G_j$ is invertible.
Let $B=E_p E_{p-1}\cdots E_1$  and 
$C = G_1G_2\cdots G_q$ 
Then $B$ and $C$ are invertible and $D = BAC$

Corollary 2

(a) - $rank(A^T) = rank(A)$ 
(b) - the rank of any matrix equal the maximum number of linearly independent rows (or columns); that is, the rank if a matrix is the dimension of the subspace generated by its rows.
(c) - The rows and columns of any matrix generate subspaces of the same dimension, numerically equal to the rank of the matrix. 

Corollary 3
Every Invertible matrix is a product of elementary matrices